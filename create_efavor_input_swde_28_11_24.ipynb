{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86cc4aff",
   "metadata": {},
   "source": [
    "## Notebook for creating efavor files for running the SWDE case study\n",
    "\n",
    "### T. Janus, 28-11-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2861f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library import\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from pyfavor.utils import hr_to_sec, hr_to_min, read_table, find_os, install_package\n",
    "from pyfavor.create import (\n",
    "    create_times_df, create_inlets_df, create_flows_df, create_pressures_df, \n",
    "    get_logger_info, get_notes, write_efavor_pressures, read_pressure_setpoints)\n",
    "# Input file names\n",
    "pressure_measurement_file = pathlib.Path(\n",
    "    \"efavor/swde_case_study/bul_data/pressure_measurements.xlsx\")\n",
    "# Output file names\n",
    "logger_file = pathlib.Path(\"efavor/swde_case_study/outputs/logger_file.xlsx\")\n",
    "pressure_measurement_file_filled = pathlib.Path(\n",
    "    \"efavor/swde_case_study/outputs/pressure_measurements_filled.xlsx\")\n",
    "# Constants and global variables\n",
    "inlet_name: str = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4840e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing value imputer for pressure dataset\n",
    "# Create a report for imputed values\n",
    "imputed_report = []\n",
    "\n",
    "# Function to impute missing pressure values in the pressure measurement dataframe\n",
    "def impute_values(group):\n",
    "    missing = group[group[\"Pressure\"].isna()]\n",
    "    for idx in missing.index:\n",
    "        imputed_value = group.loc[:idx, \"Pressure\"].mean()\n",
    "        imputed_report.append(\n",
    "            {\"Time\": idx[0], \"node\": idx[1], \"Imputed_Pressure\": imputed_value})\n",
    "        group.at[idx, \"Pressure\"] = imputed_value\n",
    "    return group\n",
    "\n",
    "# Define the function for the pipeline\n",
    "def convert_pressure_to_metres_h2o(df):\n",
    "    df[\"Pressure\"] = df[\"Pressure\"] * 10.1972\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be936a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a.Read logger data from pressure data file\n",
    "inlet_nodes = [\"J465\"]\n",
    "start_logger_id: int = 1\n",
    "# Find unique nodes from the pressure measurement file\n",
    "nodes_list = list(pd.read_excel(pressure_measurement_file).\\\n",
    "    loc[:,'_node'].unique())\n",
    "print(f\"Found {len(nodes_list)} unique nodes in the pressure data file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b Create the logger data file\n",
    "column_values = {\n",
    "    \"Logger ID\": None, \n",
    "    \"Nearest Node ID (EPANET Junction ID)\": nodes_list, \n",
    "    \"Logger Elevation (use -1000 if the same as node elevation) [m]\": -1_000,\n",
    "    \"Is inlet node? (true/false)\": \"False\"\n",
    "}\n",
    "df_logger_dict = {}\n",
    "for col_name, values in column_values.items():\n",
    "    if col_name == \"Logger ID\":\n",
    "        df_logger_dict[col_name] = list(range(start_logger_id, len(nodes_list)+start_logger_id))\n",
    "    elif isinstance(values, list):\n",
    "        df_logger_dict[col_name] = values\n",
    "    else:\n",
    "        df_logger_dict[col_name] = [values for _ in range(0,len(nodes_list))]\n",
    "\n",
    "df_logger = pd.DataFrame.from_dict(df_logger_dict, orient='columns').set_index(\"Logger ID\")\n",
    "df_logger.loc[1,\"Is inlet node? (true/false)\"] = \"True\"\n",
    "notes_data = [[\"Logger neighbourhood parameter = 0\"], \n",
    "              [\"Head difference tolerance parameter [m] = 0.01\"]]\n",
    "notes_df = pd.DataFrame(notes_data)\n",
    "with pd.ExcelWriter(logger_file, engine=\"openpyxl\") as writer:\n",
    "    df_logger.to_excel(writer, sheet_name=\"loggers\", index=True)\n",
    "    notes_df.to_excel(writer, sheet_name=\"notes\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e226ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the efavor input file\n",
    "logger_info = get_logger_info(logger_file)\n",
    "notes = get_notes(logger_file)\n",
    "junction_ids = logger_info['Nearest Node ID (EPANET Junction ID)'].to_list()\n",
    "inlet_nodes = logger_info[logger_info[\"Is inlet node? (true/false)\"] == True]\n",
    "inlet_logger_ids = inlet_nodes['Logger ID'].to_list()\n",
    "inlet_logger_junction_ids = inlet_nodes['Nearest Node ID (EPANET Junction ID)'].to_list()\n",
    "# Create a mapping between logger IDs and EPANET Junction IDS\n",
    "epanet_to_logger_id_map = \\\n",
    "    dict(zip(logger_info['Nearest Node ID (EPANET Junction ID)'], logger_info['Logger ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53953d42",
   "metadata": {},
   "source": [
    "## Fill missing values in the pressure spreadsheet and save to a new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3818deae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fill in missing rows\n",
    "def fill_missing_values(df):\n",
    "    # Create an empty list to store new rows\n",
    "    new_rows = []\n",
    "    # Iterate over each node group\n",
    "    for node, group in df.groupby('_node'):\n",
    "        # Create a time range from 01:05:00 to 04:00:00 with 5-minute intervals\n",
    "        full_time_range = pd.date_range(\n",
    "            start=\"2024-11-20 01:05:00\", \n",
    "            end=\"2024-11-20 04:00:00\", \n",
    "            freq='5T')\n",
    "        # Reindex the group to include all times in the full time range\n",
    "        group = group.set_index('Time').reindex(\n",
    "            full_time_range, method=None).reset_index()\n",
    "        group.rename(columns={'index': 'Time'}, inplace=True)\n",
    "        # Iterate over the rows to fill missing data\n",
    "        for i in range(1, len(group)):\n",
    "            # Only fill missing rows (NaN values)\n",
    "            if pd.isna(group.loc[i, \"Pressure\"]):\n",
    "                # Get the previous and next values for Pressure\n",
    "                prev_value = group.loc[i - 1, \"Pressure\"]\n",
    "                next_value = group.loc[i + 1, \"Pressure\"] if i + 1 < len(group) else prev_value\n",
    "                # Handle edge cases (01:05:00 and 04:00:00)\n",
    "                if group.loc[i, \"Time\"] == pd.Timestamp(\"2024-11-20 01:05:00\"):\n",
    "                    group.at[i, \"Pressure\"] = group.loc[i + 1, \"Pressure\"]  # Use 01:10:00 value\n",
    "                    group.at[i, \"_node\"] = group.loc[i + 1, \"_node\"]  # Use downstream node\n",
    "                elif group.loc[i, \"Time\"] == pd.Timestamp(\"2024-11-20 04:00:00\"):\n",
    "                    group.at[i, \"Pressure\"] = group.loc[i - 1, \"Pressure\"]  # Use 03:55:00 value\n",
    "                    group.at[i, \"_node\"] = group.loc[i - 1, \"_node\"]  # Use upstream node\n",
    "                else:\n",
    "                    group.at[i, \"Pressure\"] = (prev_value + next_value) / 2  # Mean of previous and next\n",
    "                    group.at[i, \"_node\"] = group.loc[i + 1, \"_node\"]  # Use downstream node\n",
    "        # Append the filled group to the new rows list\n",
    "        new_rows.append(group)\n",
    "    # Concatenate all the filled groups back together\n",
    "    return pd.concat(new_rows)\n",
    "\n",
    "pressure_measurements = pd.read_excel(pressure_measurement_file)\n",
    "pressure_measurements = pressure_measurements.sort_values(by=[\"_node\", \"Time\"])\n",
    "pressure_measurements_filled = fill_missing_values(pressure_measurements)\n",
    "pressure_measurements_filled.to_excel(pressure_measurement_file_filled, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bdf65b",
   "metadata": {},
   "source": [
    "## Create individual sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541085e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pressures dataframe\n",
    "swde_data = pd.read_excel(pressure_measurement_file_filled)\\\n",
    "    .pipe(convert_pressure_to_metres_h2o)\\\n",
    "    .rename(columns={\"_node\": \"node\"})\\\n",
    "    .set_index(\"Time\")\\\n",
    "    .loc[lambda x: ~x.index.isna()]\\\n",
    "    .loc[lambda x: x.index.time >= pd.to_datetime(\"01:05:00\").time()]\\\n",
    "    .groupby(\"node\")\\\n",
    "    .resample('15T', label='right', closed='right')\\\n",
    "    .mean()\\\n",
    "    .reset_index()\\\n",
    "    .pivot(index='Time', columns='node', values='Pressure')\n",
    "\n",
    "swde_data_efavor = swde_data\\\n",
    "    .assign(Inlet=lambda x: \"A\")\\\n",
    "    .set_index(\"Inlet\")\\\n",
    "    .rename(columns=epanet_to_logger_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "swde_data_efavor = swde_data_efavor[sorted(swde_data_efavor.columns, key=lambda x: int(x))]\n",
    "swde_data_efavor.head(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
